{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import nltk\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "token_unknown = 'UNK'\n",
    "token_start = 'START'\n",
    "token_end = 'END'\n",
    "vocab_size = 8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_name='data/reddit-comments-2015-08.csv'\n",
    "with open(file_name,'r') as f:\n",
    "    reader = csv.reader(f, skipinitialspace=True)\n",
    "    reader.__next__()\n",
    "    # split comments into sentences\n",
    "    sentences = itertools.chain(*[nltk.sent_tokenize(x[0].lower()) for x in data])\n",
    "    sentences = ['{0} {1} {2}'.format(token_start,x,token_end) for x in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_data = data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nltk.sent_tokenize(_data.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> read_data function complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import importlib as I\n",
    "import gen_data\n",
    "I.reload(gen_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read_data in action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentences = gen_data.read_data(file_name='data/reddit-comments-2015-08.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentences[0],sentences[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Need to tokenize sentences to words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenized_sentences = [ nltk.word_tokenize(sentence) for sentence in sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Frequency Distribution\n",
    "word_freq = nltk.FreqDist(itertools.chain(*tokenized_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build index2word and word2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = word_freq.most_common(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = word_freq.most_common(vocab_size-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index2word = [ x[0] for x in vocab ]\n",
    "index2word.append(token_unknown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2index = dict( [(w,i) for i,w in enumerate(index2word)] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word2index['silly']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace words not in vocabulary with unknown token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i,sent in enumerate(tokenized_sentences):\n",
    "    tokenized_sentences[i] = [ w if w in index2word else token_unknown for w in sent ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenized_sentences[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = np.asarray( [ [word2index[w] for w in sent[:-1] ] for sent in tokenized_sentences])\n",
    "Y_train = np.asarray( [ [word2index[w] for w in sent[1:] ] for sent in tokenized_sentences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = {'vocab' : vocab, 'word2index' : word2index, 'index2word' : index2word, 'X_train' : X_train, 'Y_train' : Y_train}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle as p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('data/pdata.pkl','wb') as f:\n",
    "    p.dump(data,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gen_data.py complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gen_data\n",
    "import importlib as I\n",
    "I.reload(gen_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = gen_data.execute(data_file='data/reddit-comments-2015-08.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = utils.read_pickle(pkl_file='data/pdata.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['Y_train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The utils.py module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(utils.decode_sentence(data_['X_train'][500], data_['index2word']))\n",
    "print(utils.decode_sentence(data_['Y_train'][500], data_['index2word']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNNNumpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.argmax?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import models\n",
    "I.reload(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(171)\n",
    "model = models.RNNNumpy(gen_data.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "op, s = model.forward(data['X_train'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "op_ = model.predict(data['X_train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "utils.decode_sentence(op_,data['index2word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cpr = op[np.arange(len(data['Y_train'][1])), data['Y_train'][1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(data['Y_train'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cpr1 = op[,data['Y_train'][1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cpr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for 1000 examples\n",
    "print('Expected Loss : {}'.format(np.log(gen_data.vocab_size)))\n",
    "print('Actual Loss : {}'.format(model.loss(data['X_train'][:1000],data['Y_train'][:1000])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training : SGD, BPTT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import train\n",
    "I.reload(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.sgd(model, X_train=data['X_train'][:100], Y_train=data['Y_train'][:100],nepoch=10,eval_after=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducing Theano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "import theano.tensor as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = T.matrix('X')\n",
    "y = T.lvector('y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idim = 2\n",
    "odim = 2\n",
    "hdim = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W1 = theano.shared(np.random.randn(idim,hdim))\n",
    "b1 = theano.shared(np.random.randn(hdim))\n",
    "W2 = theano.shared(np.random.randn(hdim,odim))\n",
    "b2 = theano.shared(np.random.randn(odim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# forward\n",
    "z1 = T.tanh(X.dot(W1) + b1)\n",
    "y_ = T.nnet.softmax(z1.dot(W2) + b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = T.nnet.categorical_crossentropy(y_, y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = T.argmax(y_,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction.eval({X : [[11,27]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theano.printing.debugprint(y_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dW1 = T.grad(loss,W1)\n",
    "db1 = T.grad(loss,b1)\n",
    "dW2 = T.grad(loss,W2)\n",
    "db2 = T.grad(loss,b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from theano.printing import debugprint as dbp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dbp(dW1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gradient_step = theano.function([X,y], updates= {\n",
    "        W1 : W1 - lr*dW1,\n",
    "        W2 : W2 - lr*dW2,\n",
    "        b1 : b1 - lr*db1,\n",
    "        b2 : b2 - lr*db2\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(2)\n",
    "# reinit shared var\n",
    "W1.set_value(np.random.randn(idim,hdim)/np.sqrt(idim))\n",
    "b1.set_value(np.zeros(hdim))\n",
    "W2.set_value(np.random.randn(hdim,odim)/np.sqrt(hdim))\n",
    "b2.set_value(np.zeros(odim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X, train_y = sklearn.datasets.make_moons(5000, noise=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_X = train_X.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nepoch = 20000\n",
    "for i in range(nepoch):\n",
    "    gradient_step(train_X,train_y)\n",
    "    if not i%1000:\n",
    "        print('Loss : {}'.format(loss.eval({X:train_X, y:train_y})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction.eval({X: [[-1.5,-0.5]]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN in Theano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scan "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = T.iscalar('i')\n",
    "results, updates = theano.scan(fn=lambda x : x+1, sequences=None, outputs_info=0,n_steps=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = theano.function([i], results, updates=updates)\n",
    "f(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initial 2 values\n",
    "x0 = T.ivector('x0')\n",
    "results, updates = theano.scan(fn = lambda a,b : a+b, outputs_info=[ {'initial' : x0, 'taps' : [-2,-1] }],\n",
    "                               n_steps=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fib = theano.function([i,x0], results, updates=updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fib(20,[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flow Control in Loop using scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fibo(a,b):\n",
    "    return a+b, theano.scan_module.until(a+b<0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results, updates = theano.scan(fibo, outputs_info= [{'initial' : x0, 'taps' : [-2,-1]}],\n",
    "                               n_steps = i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fib_opt = theano.function([i,x0], results, updates=updates)\n",
    "fib_opt(50,[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fib(50,[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xv = T.vector('xv')\n",
    "results, updates = theano.scan(fn=lambda a,b :a, outputs_info=0.0, sequences=xv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iter_xv = theano.function([xv],results,updates=updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xv_val = np.array([4.,8,29,1,3,8,1,3]).astype(np.float32)\n",
    "iter_xv(xv_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "I.reload(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theano_model = models.RNNTheano(gen_data.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theano_model.sgd_step(data['X_train'][12], data['Y_train'][12], 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "I.reload(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.sgd(theano_model, X_train=data['X_train'][:100], Y_train=data['Y_train'][:100],nepoch=1000,eval_after=100,lr=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "op = theano_model.predict(data['X_train'][12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "utils.decode_sentence(op, data['index2word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import importlib as I\n",
    "import utils\n",
    "I.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import models\n",
    "I.reload(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gen_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "theano_model = models.RNNTheano(gen_data.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "utils.load_npz(path='saved/trained-model-theano.npz',model=theano_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = utils.read_pickle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(data['X_train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theano_model.U.get_value().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "op = theano_model.predict(data['X_train'][113])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "utils.decode_sentence(op,data['index2word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "op = theano_model.forward([data['word2index'][gen_data.token_unknown]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "op[-1]\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nom = np.random.multinomial(10,op[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.argmax(op[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "op1 = op[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.multinomial(1,np.argsort(op[-1])[-10:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.choice([1,2,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "op[-1].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nom.nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nom.argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "I.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theano_model.loss(data['X_train'][300:400], data['Y_train'][300:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "utils.gen_sentences(model = theano_model, \n",
    "                    word2index=data['word2index'],\n",
    "                    index2word = data['index2word'],\n",
    "                    num_sent = 10,\n",
    "                    sent_min_len = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.sort(np.array([5,1,2,7]))[-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX 960 (CNMeM is disabled, cuDNN 4007)\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "import importlib as I\n",
    "import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = utils.read_pickle(pkl_file='data/pdata.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "I.reload(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR (theano.gof.opt): Optimization failure due to: local_gpu_softmax_with_bias\n",
      "ERROR (theano.gof.opt): node: SoftmaxWithBias(Reshape{2}.0, HostFromGpu.0)\n",
      "ERROR (theano.gof.opt): TRACEBACK:\n",
      "ERROR (theano.gof.opt): Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/gof/opt.py\", line 1772, in process_node\n",
      "    replacements = lopt.transform(node)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/sandbox/cuda/opt.py\", line 1416, in local_gpu_softmax_with_bias\n",
      "    gpu_sm = GpuSoftmaxWithBias()(as_cuda_ndarray_variable(x),\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/sandbox/cuda/basic_ops.py\", line 47, in as_cuda_ndarray_variable\n",
      "    return gpu_from_host(tensor_x)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/gof/op.py\", line 611, in __call__\n",
      "    node = self.make_node(*inputs, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/sandbox/cuda/basic_ops.py\", line 140, in make_node\n",
      "    dtype=x.dtype)()])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/sandbox/cuda/type.py\", line 93, in __init__\n",
      "    (self.__class__.__name__, dtype, name))\n",
      "TypeError: CudaNdarrayType only supports dtype float32 for now. Tried using dtype float64 for variable None\n",
      "\n",
      "ERROR (theano.gof.opt): Optimization failure due to: local_gpu_softmax_with_bias\n",
      "ERROR (theano.gof.opt): node: SoftmaxWithBias(Reshape{2}.0, HostFromGpu.0)\n",
      "ERROR (theano.gof.opt): TRACEBACK:\n",
      "ERROR (theano.gof.opt): Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/gof/opt.py\", line 1772, in process_node\n",
      "    replacements = lopt.transform(node)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/sandbox/cuda/opt.py\", line 1416, in local_gpu_softmax_with_bias\n",
      "    gpu_sm = GpuSoftmaxWithBias()(as_cuda_ndarray_variable(x),\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/sandbox/cuda/basic_ops.py\", line 47, in as_cuda_ndarray_variable\n",
      "    return gpu_from_host(tensor_x)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/gof/op.py\", line 611, in __call__\n",
      "    node = self.make_node(*inputs, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/sandbox/cuda/basic_ops.py\", line 140, in make_node\n",
      "    dtype=x.dtype)()])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/sandbox/cuda/type.py\", line 93, in __init__\n",
      "    (self.__class__.__name__, dtype, name))\n",
      "TypeError: CudaNdarrayType only supports dtype float32 for now. Tried using dtype float64 for variable None\n",
      "\n",
      "ERROR (theano.gof.opt): Optimization failure due to: local_gpu_softmax_with_bias\n",
      "ERROR (theano.gof.opt): node: SoftmaxWithBias(Reshape{2}.0, HostFromGpu.0)\n",
      "ERROR (theano.gof.opt): TRACEBACK:\n",
      "ERROR (theano.gof.opt): Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/gof/opt.py\", line 1772, in process_node\n",
      "    replacements = lopt.transform(node)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/sandbox/cuda/opt.py\", line 1416, in local_gpu_softmax_with_bias\n",
      "    gpu_sm = GpuSoftmaxWithBias()(as_cuda_ndarray_variable(x),\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/sandbox/cuda/basic_ops.py\", line 47, in as_cuda_ndarray_variable\n",
      "    return gpu_from_host(tensor_x)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/gof/op.py\", line 611, in __call__\n",
      "    node = self.make_node(*inputs, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/sandbox/cuda/basic_ops.py\", line 140, in make_node\n",
      "    dtype=x.dtype)()])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/sandbox/cuda/type.py\", line 93, in __init__\n",
      "    (self.__class__.__name__, dtype, name))\n",
      "TypeError: CudaNdarrayType only supports dtype float32 for now. Tried using dtype float64 for variable None\n",
      "\n",
      "ERROR (theano.gof.opt): Optimization failure due to: local_gpu_softmax_with_bias\n",
      "ERROR (theano.gof.opt): node: SoftmaxWithBias(Reshape{2}.0, HostFromGpu.0)\n",
      "ERROR (theano.gof.opt): TRACEBACK:\n",
      "ERROR (theano.gof.opt): Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/gof/opt.py\", line 1772, in process_node\n",
      "    replacements = lopt.transform(node)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/sandbox/cuda/opt.py\", line 1416, in local_gpu_softmax_with_bias\n",
      "    gpu_sm = GpuSoftmaxWithBias()(as_cuda_ndarray_variable(x),\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/sandbox/cuda/basic_ops.py\", line 47, in as_cuda_ndarray_variable\n",
      "    return gpu_from_host(tensor_x)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/gof/op.py\", line 611, in __call__\n",
      "    node = self.make_node(*inputs, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/sandbox/cuda/basic_ops.py\", line 140, in make_node\n",
      "    dtype=x.dtype)()])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/sandbox/cuda/type.py\", line 93, in __init__\n",
      "    (self.__class__.__name__, dtype, name))\n",
      "TypeError: CudaNdarrayType only supports dtype float32 for now. Tried using dtype float64 for variable None\n",
      "\n",
      "ERROR (theano.gof.opt): Optimization failure due to: local_gpu_softmax_with_bias\n",
      "ERROR (theano.gof.opt): node: SoftmaxWithBias(Reshape{2}.0, HostFromGpu.0)\n",
      "ERROR (theano.gof.opt): TRACEBACK:\n",
      "ERROR (theano.gof.opt): Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/gof/opt.py\", line 1772, in process_node\n",
      "    replacements = lopt.transform(node)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/sandbox/cuda/opt.py\", line 1416, in local_gpu_softmax_with_bias\n",
      "    gpu_sm = GpuSoftmaxWithBias()(as_cuda_ndarray_variable(x),\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/sandbox/cuda/basic_ops.py\", line 47, in as_cuda_ndarray_variable\n",
      "    return gpu_from_host(tensor_x)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/gof/op.py\", line 611, in __call__\n",
      "    node = self.make_node(*inputs, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/sandbox/cuda/basic_ops.py\", line 140, in make_node\n",
      "    dtype=x.dtype)()])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/sandbox/cuda/type.py\", line 93, in __init__\n",
      "    (self.__class__.__name__, dtype, name))\n",
      "TypeError: CudaNdarrayType only supports dtype float32 for now. Tried using dtype float64 for variable None\n",
      "\n",
      "ERROR (theano.gof.opt): Optimization failure due to: local_gpu_softmax_with_bias\n",
      "ERROR (theano.gof.opt): node: SoftmaxWithBias(Reshape{2}.0, HostFromGpu.0)\n",
      "ERROR (theano.gof.opt): TRACEBACK:\n",
      "ERROR (theano.gof.opt): Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/gof/opt.py\", line 1772, in process_node\n",
      "    replacements = lopt.transform(node)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/sandbox/cuda/opt.py\", line 1416, in local_gpu_softmax_with_bias\n",
      "    gpu_sm = GpuSoftmaxWithBias()(as_cuda_ndarray_variable(x),\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/sandbox/cuda/basic_ops.py\", line 47, in as_cuda_ndarray_variable\n",
      "    return gpu_from_host(tensor_x)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/gof/op.py\", line 611, in __call__\n",
      "    node = self.make_node(*inputs, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/sandbox/cuda/basic_ops.py\", line 140, in make_node\n",
      "    dtype=x.dtype)()])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/sandbox/cuda/type.py\", line 93, in __init__\n",
      "    (self.__class__.__name__, dtype, name))\n",
      "TypeError: CudaNdarrayType only supports dtype float32 for now. Tried using dtype float64 for variable None\n",
      "\n",
      "ERROR (theano.gof.opt): Optimization failure due to: local_gpu_softmax_with_bias\n",
      "ERROR (theano.gof.opt): node: SoftmaxWithBias(Reshape{2}.0, HostFromGpu.0)\n",
      "ERROR (theano.gof.opt): TRACEBACK:\n",
      "ERROR (theano.gof.opt): Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/gof/opt.py\", line 1772, in process_node\n",
      "    replacements = lopt.transform(node)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/sandbox/cuda/opt.py\", line 1416, in local_gpu_softmax_with_bias\n",
      "    gpu_sm = GpuSoftmaxWithBias()(as_cuda_ndarray_variable(x),\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/sandbox/cuda/basic_ops.py\", line 47, in as_cuda_ndarray_variable\n",
      "    return gpu_from_host(tensor_x)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/gof/op.py\", line 611, in __call__\n",
      "    node = self.make_node(*inputs, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/sandbox/cuda/basic_ops.py\", line 140, in make_node\n",
      "    dtype=x.dtype)()])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/sandbox/cuda/type.py\", line 93, in __init__\n",
      "    (self.__class__.__name__, dtype, name))\n",
      "TypeError: CudaNdarrayType only supports dtype float32 for now. Tried using dtype float64 for variable None\n",
      "\n",
      "ERROR (theano.gof.opt): Optimization failure due to: local_gpu_softmax_with_bias\n",
      "ERROR (theano.gof.opt): node: SoftmaxWithBias(Reshape{2}.0, HostFromGpu.0)\n",
      "ERROR (theano.gof.opt): TRACEBACK:\n",
      "ERROR (theano.gof.opt): Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/gof/opt.py\", line 1772, in process_node\n",
      "    replacements = lopt.transform(node)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/sandbox/cuda/opt.py\", line 1416, in local_gpu_softmax_with_bias\n",
      "    gpu_sm = GpuSoftmaxWithBias()(as_cuda_ndarray_variable(x),\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/sandbox/cuda/basic_ops.py\", line 47, in as_cuda_ndarray_variable\n",
      "    return gpu_from_host(tensor_x)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/gof/op.py\", line 611, in __call__\n",
      "    node = self.make_node(*inputs, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/sandbox/cuda/basic_ops.py\", line 140, in make_node\n",
      "    dtype=x.dtype)()])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/sandbox/cuda/type.py\", line 93, in __init__\n",
      "    (self.__class__.__name__, dtype, name))\n",
      "TypeError: CudaNdarrayType only supports dtype float32 for now. Tried using dtype float64 for variable None\n",
      "\n",
      "ERROR (theano.gof.opt): Optimization failure due to: local_gpu_softmax_with_bias\n",
      "ERROR (theano.gof.opt): node: SoftmaxWithBias(Reshape{2}.0, HostFromGpu.0)\n",
      "ERROR (theano.gof.opt): TRACEBACK:\n",
      "ERROR (theano.gof.opt): Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/gof/opt.py\", line 1772, in process_node\n",
      "    replacements = lopt.transform(node)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/sandbox/cuda/opt.py\", line 1416, in local_gpu_softmax_with_bias\n",
      "    gpu_sm = GpuSoftmaxWithBias()(as_cuda_ndarray_variable(x),\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/sandbox/cuda/basic_ops.py\", line 47, in as_cuda_ndarray_variable\n",
      "    return gpu_from_host(tensor_x)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/gof/op.py\", line 611, in __call__\n",
      "    node = self.make_node(*inputs, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/sandbox/cuda/basic_ops.py\", line 140, in make_node\n",
      "    dtype=x.dtype)()])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/sandbox/cuda/type.py\", line 93, in __init__\n",
      "    (self.__class__.__name__, dtype, name))\n",
      "TypeError: CudaNdarrayType only supports dtype float32 for now. Tried using dtype float64 for variable None\n",
      "\n",
      "ERROR (theano.gof.opt): Optimization failure due to: local_gpu_softmax_with_bias\n",
      "ERROR (theano.gof.opt): node: SoftmaxWithBias(Reshape{2}.0, HostFromGpu.0)\n",
      "ERROR (theano.gof.opt): TRACEBACK:\n",
      "ERROR (theano.gof.opt): Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/gof/opt.py\", line 1772, in process_node\n",
      "    replacements = lopt.transform(node)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/sandbox/cuda/opt.py\", line 1416, in local_gpu_softmax_with_bias\n",
      "    gpu_sm = GpuSoftmaxWithBias()(as_cuda_ndarray_variable(x),\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/sandbox/cuda/basic_ops.py\", line 47, in as_cuda_ndarray_variable\n",
      "    return gpu_from_host(tensor_x)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/gof/op.py\", line 611, in __call__\n",
      "    node = self.make_node(*inputs, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/sandbox/cuda/basic_ops.py\", line 140, in make_node\n",
      "    dtype=x.dtype)()])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/sandbox/cuda/type.py\", line 93, in __init__\n",
      "    (self.__class__.__name__, dtype, name))\n",
      "TypeError: CudaNdarrayType only supports dtype float32 for now. Tried using dtype float64 for variable None\n",
      "\n",
      "ERROR (theano.gof.opt): Optimization failure due to: local_gpu_softmax_with_bias\n",
      "ERROR (theano.gof.opt): node: SoftmaxWithBias(Reshape{2}.0, HostFromGpu.0)\n",
      "ERROR (theano.gof.opt): TRACEBACK:\n",
      "ERROR (theano.gof.opt): Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/gof/opt.py\", line 1772, in process_node\n",
      "    replacements = lopt.transform(node)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/sandbox/cuda/opt.py\", line 1416, in local_gpu_softmax_with_bias\n",
      "    gpu_sm = GpuSoftmaxWithBias()(as_cuda_ndarray_variable(x),\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/sandbox/cuda/basic_ops.py\", line 47, in as_cuda_ndarray_variable\n",
      "    return gpu_from_host(tensor_x)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/gof/op.py\", line 611, in __call__\n",
      "    node = self.make_node(*inputs, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/sandbox/cuda/basic_ops.py\", line 140, in make_node\n",
      "    dtype=x.dtype)()])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/sandbox/cuda/type.py\", line 93, in __init__\n",
      "    (self.__class__.__name__, dtype, name))\n",
      "TypeError: CudaNdarrayType only supports dtype float32 for now. Tried using dtype float64 for variable None\n",
      "\n",
      "ERROR (theano.gof.opt): Optimization failure due to: local_gpu_softmax_with_bias\n",
      "ERROR (theano.gof.opt): node: SoftmaxWithBias(Reshape{2}.0, HostFromGpu.0)\n",
      "ERROR (theano.gof.opt): TRACEBACK:\n",
      "ERROR (theano.gof.opt): Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/gof/opt.py\", line 1772, in process_node\n",
      "    replacements = lopt.transform(node)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/sandbox/cuda/opt.py\", line 1416, in local_gpu_softmax_with_bias\n",
      "    gpu_sm = GpuSoftmaxWithBias()(as_cuda_ndarray_variable(x),\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/sandbox/cuda/basic_ops.py\", line 47, in as_cuda_ndarray_variable\n",
      "    return gpu_from_host(tensor_x)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/gof/op.py\", line 611, in __call__\n",
      "    node = self.make_node(*inputs, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/sandbox/cuda/basic_ops.py\", line 140, in make_node\n",
      "    dtype=x.dtype)()])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/sandbox/cuda/type.py\", line 93, in __init__\n",
      "    (self.__class__.__name__, dtype, name))\n",
      "TypeError: CudaNdarrayType only supports dtype float32 for now. Tried using dtype float64 for variable None\n",
      "\n",
      "ERROR (theano.gof.opt): Optimization failure due to: local_gpu_softmax_with_bias\n",
      "ERROR (theano.gof.opt): node: SoftmaxWithBias(Reshape{2}.0, HostFromGpu.0)\n",
      "ERROR (theano.gof.opt): TRACEBACK:\n",
      "ERROR (theano.gof.opt): Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/gof/opt.py\", line 1772, in process_node\n",
      "    replacements = lopt.transform(node)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/sandbox/cuda/opt.py\", line 1416, in local_gpu_softmax_with_bias\n",
      "    gpu_sm = GpuSoftmaxWithBias()(as_cuda_ndarray_variable(x),\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/sandbox/cuda/basic_ops.py\", line 47, in as_cuda_ndarray_variable\n",
      "    return gpu_from_host(tensor_x)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/gof/op.py\", line 611, in __call__\n",
      "    node = self.make_node(*inputs, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/sandbox/cuda/basic_ops.py\", line 140, in make_node\n",
      "    dtype=x.dtype)()])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/sandbox/cuda/type.py\", line 93, in __init__\n",
      "    (self.__class__.__name__, dtype, name))\n",
      "TypeError: CudaNdarrayType only supports dtype float32 for now. Tried using dtype float64 for variable None\n",
      "\n",
      "ERROR (theano.gof.opt): Optimization failure due to: local_gpu_softmax_with_bias\n",
      "ERROR (theano.gof.opt): node: SoftmaxWithBias(Reshape{2}.0, HostFromGpu.0)\n",
      "ERROR (theano.gof.opt): TRACEBACK:\n",
      "ERROR (theano.gof.opt): Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/gof/opt.py\", line 1772, in process_node\n",
      "    replacements = lopt.transform(node)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/sandbox/cuda/opt.py\", line 1416, in local_gpu_softmax_with_bias\n",
      "    gpu_sm = GpuSoftmaxWithBias()(as_cuda_ndarray_variable(x),\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/sandbox/cuda/basic_ops.py\", line 47, in as_cuda_ndarray_variable\n",
      "    return gpu_from_host(tensor_x)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/gof/op.py\", line 611, in __call__\n",
      "    node = self.make_node(*inputs, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/sandbox/cuda/basic_ops.py\", line 140, in make_node\n",
      "    dtype=x.dtype)()])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/sandbox/cuda/type.py\", line 93, in __init__\n",
      "    (self.__class__.__name__, dtype, name))\n",
      "TypeError: CudaNdarrayType only supports dtype float32 for now. Tried using dtype float64 for variable None\n",
      "\n",
      "ERROR (theano.gof.opt): Optimization failure due to: local_gpu_softmax_with_bias\n",
      "ERROR (theano.gof.opt): node: SoftmaxWithBias(Reshape{2}.0, HostFromGpu.0)\n",
      "ERROR (theano.gof.opt): TRACEBACK:\n",
      "ERROR (theano.gof.opt): Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/gof/opt.py\", line 1772, in process_node\n",
      "    replacements = lopt.transform(node)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/sandbox/cuda/opt.py\", line 1416, in local_gpu_softmax_with_bias\n",
      "    gpu_sm = GpuSoftmaxWithBias()(as_cuda_ndarray_variable(x),\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/sandbox/cuda/basic_ops.py\", line 47, in as_cuda_ndarray_variable\n",
      "    return gpu_from_host(tensor_x)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/gof/op.py\", line 611, in __call__\n",
      "    node = self.make_node(*inputs, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/sandbox/cuda/basic_ops.py\", line 140, in make_node\n",
      "    dtype=x.dtype)()])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/sandbox/cuda/type.py\", line 93, in __init__\n",
      "    (self.__class__.__name__, dtype, name))\n",
      "TypeError: CudaNdarrayType only supports dtype float32 for now. Tried using dtype float64 for variable None\n",
      "\n",
      "ERROR (theano.gof.opt): Optimization failure due to: local_gpu_softmax_with_bias\n",
      "ERROR (theano.gof.opt): node: SoftmaxWithBias(Reshape{2}.0, HostFromGpu.0)\n",
      "ERROR (theano.gof.opt): TRACEBACK:\n",
      "ERROR (theano.gof.opt): Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/gof/opt.py\", line 1772, in process_node\n",
      "    replacements = lopt.transform(node)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/sandbox/cuda/opt.py\", line 1416, in local_gpu_softmax_with_bias\n",
      "    gpu_sm = GpuSoftmaxWithBias()(as_cuda_ndarray_variable(x),\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/sandbox/cuda/basic_ops.py\", line 47, in as_cuda_ndarray_variable\n",
      "    return gpu_from_host(tensor_x)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/gof/op.py\", line 611, in __call__\n",
      "    node = self.make_node(*inputs, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/sandbox/cuda/basic_ops.py\", line 140, in make_node\n",
      "    dtype=x.dtype)()])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/theano/sandbox/cuda/type.py\", line 93, in __init__\n",
      "    (self.__class__.__name__, dtype, name))\n",
      "TypeError: CudaNdarrayType only supports dtype float32 for now. Tried using dtype float64 for variable None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gru_model = models.GRUTheano(8000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "op = gru_model.predict(data['X_train'][12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'type assure vaccines invisible badass election F Five'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.decode_sentence(op, data['index2word'], data['word2index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'train' from '/home/suriya/_/rnn/gen_text/train.py'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I.reload(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5061055982491482% complete."
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-7c88dabdcfd3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msgd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgru_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X_train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Y_train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meval_after\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/suriya/_/rnn/gen_text/train.py\u001b[0m in \u001b[0;36msgd\u001b[0;34m(model, X_train, Y_train, lr, decay, nepoch, eval_after)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;31m# sgd step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msgd_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0mnum_examples_seen\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\r{0}% complete.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnepoch\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'position_of_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/theano/scan_module/scan_op.py\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n, allow_gc)\u001b[0m\n\u001b[1;32m    949\u001b[0m         def rval(p=p, i=node_input_storage, o=node_output_storage, n=node,\n\u001b[1;32m    950\u001b[0m                  allow_gc=allow_gc):\n\u001b[0;32m--> 951\u001b[0;31m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    952\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m                 \u001b[0mcompute_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/theano/scan_module/scan_op.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(node, args, outs)\u001b[0m\n\u001b[1;32m    938\u001b[0m                         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m                         \u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 940\u001b[0;31m                         self, node)\n\u001b[0m\u001b[1;32m    941\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mImportError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgof\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMissingGXX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m             \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mtheano/scan_module/scan_perform.pyx\u001b[0m in \u001b[0;36mtheano.scan_module.scan_perform.perform (/home/suriya/.theano/compiledir_Linux-4.4--generic-x86_64-with-Ubuntu-16.04-xenial-x86_64-3.5.1+-64/scan_perform/mod.cpp:4193)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/theano/gof/op.py\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n)\u001b[0m\n\u001b[1;32m    910\u001b[0m             \u001b[0;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m                 \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m                     \u001b[0mcompute_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/theano/tensor/basic.py\u001b[0m in \u001b[0;36mperform\u001b[0;34m(self, node, inp, out)\u001b[0m\n\u001b[1;32m   5434\u001b[0m         \u001b[0;31m# gives a numpy float object but we need to return a 0d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5435\u001b[0m         \u001b[0;31m# ndarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5436\u001b[0;31m         \u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5438\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train.sgd(gru_model, X_train=data['X_train'], Y_train=data['Y_train'],nepoch=10,eval_after=1,lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def io(n):\n",
    "    print('I : {}'.format(utils.decode_sentence(data['X_train'][n], data['index2word'], data['word2index'])))\n",
    "    print('O : {}'.format(utils.decode_sentence(gru_model.predict(data['X_train'][n]), data['index2word'], data['word2index'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I : Unfortunately , your post has been removed due to having a very short title .\n",
      "O : It a the It . . the . .\n"
     ]
    }
   ],
   "source": [
    "io(187)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
